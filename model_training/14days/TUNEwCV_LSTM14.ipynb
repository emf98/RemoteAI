{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952b7306",
   "metadata": {},
   "source": [
    "### Tuning the LSTM model ... \n",
    "\n",
    "File initially created 5/28/2025. \n",
    "\n",
    "I will start with a 14 day model.\n",
    "\n",
    "I will need to tune by region. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80fe58",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c354a55",
   "metadata": {},
   "source": [
    "!pip install netCDF4\n",
    "!pip install matplotlib\n",
    "!pip install cartopy\n",
    "#!pip install investigate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6597c323",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "!pip uninstall -y libtpu libtpu-nightly\n",
    "!pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
   ]
  },
  {
   "cell_type": "raw",
   "id": "494f8248",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import jax\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7416931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 00:36:35.432419: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 00:36:35.463849: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 00:36:35.463870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 00:36:35.464808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 00:36:35.469888: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 00:36:36.840715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 75522 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:2d:00.0, compute capability: 9.0\n"
     ]
    }
   ],
   "source": [
    "##import cell makes its appearance once again...\n",
    "%matplotlib inline\n",
    "##so-called \"math\" related imports\n",
    "#from netCDF4 import Dataset as ncread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import xarray as xr\n",
    "\n",
    "import pickle\n",
    "\n",
    "##plotting related imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow/keras related files\n",
    "import tensorflow as tf    \n",
    "#tf.compat.v1.disable_v2_behavior() # <-- HERE !\n",
    "\n",
    "tf.device('/physical_device:GPU:0')\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Activation, Reshape, Flatten, LSTM, Dense, Dropout, Embedding, Bidirectional, GRU\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#import investigate\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ada2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55f0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EOF_def import EOF_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bbe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load in solvers for PC analysis to get the PCs for the model itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input solvers\n",
    "infile = open(\"../../eof_analysis/solvers/Usolver_14.p\",\"rb\",)\n",
    "Usolver = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../eof_analysis/solvers/EHFsolver_14.p\",\"rb\",)\n",
    "EHFsolver = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../eof_analysis/solvers/GPHsolver_14.p\",\"rb\",)\n",
    "GPHsolver = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3256e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8370, 10)\n"
     ]
    }
   ],
   "source": [
    "## U\n",
    "U_EOF_nw, U_EOF_nw2d, U_eigenv, U_VarEx, U_PC = EOF_def(Usolver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf6278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8370, 45)\n"
     ]
    }
   ],
   "source": [
    "## EHF\n",
    "EHF_EOF_nw, EHF_EOF_nw2d, EHF_eigenv, EHF_VarEx, EHF_PC = EOF_def(EHFsolver, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4ca153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8370, 10)\n"
     ]
    }
   ],
   "source": [
    "## GPH\n",
    "GPH_EOF_nw, GPH_EOF_nw2d, GPH_eigenv, GPH_VarEx, GPH_PC = EOF_def(GPHsolver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7d5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove PC 1\n",
    "U_PC = U_PC[:, 1:]\n",
    "EHF_PC = EHF_PC[:, 1:]\n",
    "GPH_PC = GPH_PC[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874d864b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load output data\n",
    "infile = open(\"../../eof_data/seus_anomtemps.p\",\"rb\",)\n",
    "output = pickle.load(infile) \n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3feb3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create one array of PCs\n",
    "inputvar = np.concatenate((U_PC,EHF_PC,GPH_PC),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892e712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.771931</td>\n",
       "      <td>-1.799955</td>\n",
       "      <td>1.313722</td>\n",
       "      <td>-1.630033</td>\n",
       "      <td>0.566290</td>\n",
       "      <td>1.589922</td>\n",
       "      <td>-0.172617</td>\n",
       "      <td>1.566368</td>\n",
       "      <td>0.659295</td>\n",
       "      <td>0.199667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379306</td>\n",
       "      <td>1.641585</td>\n",
       "      <td>-0.743088</td>\n",
       "      <td>-0.070795</td>\n",
       "      <td>0.742423</td>\n",
       "      <td>0.454864</td>\n",
       "      <td>0.251855</td>\n",
       "      <td>0.795493</td>\n",
       "      <td>-0.417825</td>\n",
       "      <td>-1.029987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803999</td>\n",
       "      <td>-1.900528</td>\n",
       "      <td>1.245334</td>\n",
       "      <td>-1.692496</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>2.042962</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>1.506671</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.238603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347120</td>\n",
       "      <td>1.752066</td>\n",
       "      <td>-0.985741</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.764168</td>\n",
       "      <td>0.594407</td>\n",
       "      <td>0.432133</td>\n",
       "      <td>1.080915</td>\n",
       "      <td>-0.165571</td>\n",
       "      <td>-1.420320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.872130</td>\n",
       "      <td>-2.032226</td>\n",
       "      <td>1.424598</td>\n",
       "      <td>-1.343837</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>1.711995</td>\n",
       "      <td>0.503023</td>\n",
       "      <td>0.826614</td>\n",
       "      <td>-1.105172</td>\n",
       "      <td>0.270467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585204</td>\n",
       "      <td>1.588777</td>\n",
       "      <td>-1.302961</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>0.733291</td>\n",
       "      <td>0.651646</td>\n",
       "      <td>0.515277</td>\n",
       "      <td>0.912816</td>\n",
       "      <td>0.289325</td>\n",
       "      <td>-1.499576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867914</td>\n",
       "      <td>-2.054812</td>\n",
       "      <td>1.657540</td>\n",
       "      <td>-0.838510</td>\n",
       "      <td>0.746273</td>\n",
       "      <td>1.227320</td>\n",
       "      <td>0.679350</td>\n",
       "      <td>1.134812</td>\n",
       "      <td>-0.876215</td>\n",
       "      <td>0.232273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789144</td>\n",
       "      <td>1.273398</td>\n",
       "      <td>-1.416257</td>\n",
       "      <td>-0.048546</td>\n",
       "      <td>0.671334</td>\n",
       "      <td>0.746395</td>\n",
       "      <td>0.300846</td>\n",
       "      <td>0.709486</td>\n",
       "      <td>0.123002</td>\n",
       "      <td>-0.751547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.787536</td>\n",
       "      <td>-2.011126</td>\n",
       "      <td>1.559197</td>\n",
       "      <td>-0.409157</td>\n",
       "      <td>1.239623</td>\n",
       "      <td>0.913107</td>\n",
       "      <td>0.641640</td>\n",
       "      <td>1.931937</td>\n",
       "      <td>-0.272880</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377190</td>\n",
       "      <td>1.043657</td>\n",
       "      <td>-1.369488</td>\n",
       "      <td>-0.219058</td>\n",
       "      <td>0.751703</td>\n",
       "      <td>1.057360</td>\n",
       "      <td>0.347496</td>\n",
       "      <td>0.404459</td>\n",
       "      <td>0.330464</td>\n",
       "      <td>0.215042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>0.415159</td>\n",
       "      <td>-0.170777</td>\n",
       "      <td>-0.531934</td>\n",
       "      <td>-0.397453</td>\n",
       "      <td>1.102362</td>\n",
       "      <td>-0.267771</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>1.148350</td>\n",
       "      <td>-2.241040</td>\n",
       "      <td>0.180624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.535923</td>\n",
       "      <td>1.136943</td>\n",
       "      <td>-0.416174</td>\n",
       "      <td>0.562862</td>\n",
       "      <td>-0.354710</td>\n",
       "      <td>-0.763675</td>\n",
       "      <td>-0.224326</td>\n",
       "      <td>0.846225</td>\n",
       "      <td>-1.504478</td>\n",
       "      <td>-0.403197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>0.484640</td>\n",
       "      <td>-0.232514</td>\n",
       "      <td>-0.597377</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.837373</td>\n",
       "      <td>-0.276658</td>\n",
       "      <td>0.205001</td>\n",
       "      <td>1.321532</td>\n",
       "      <td>-2.205615</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670336</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>-0.641672</td>\n",
       "      <td>0.649173</td>\n",
       "      <td>-0.423895</td>\n",
       "      <td>-0.589386</td>\n",
       "      <td>-0.034272</td>\n",
       "      <td>0.739777</td>\n",
       "      <td>-1.244535</td>\n",
       "      <td>-0.653119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8367</th>\n",
       "      <td>0.558206</td>\n",
       "      <td>-0.163820</td>\n",
       "      <td>-0.476075</td>\n",
       "      <td>0.480464</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>-0.589342</td>\n",
       "      <td>-0.360315</td>\n",
       "      <td>1.203000</td>\n",
       "      <td>-2.164044</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.172690</td>\n",
       "      <td>0.839839</td>\n",
       "      <td>-1.031493</td>\n",
       "      <td>0.910849</td>\n",
       "      <td>-0.425116</td>\n",
       "      <td>-0.327954</td>\n",
       "      <td>0.842602</td>\n",
       "      <td>1.100344</td>\n",
       "      <td>-0.612106</td>\n",
       "      <td>-0.448852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8368</th>\n",
       "      <td>0.591930</td>\n",
       "      <td>0.343880</td>\n",
       "      <td>-0.538673</td>\n",
       "      <td>1.014618</td>\n",
       "      <td>0.200438</td>\n",
       "      <td>-0.391132</td>\n",
       "      <td>-0.570871</td>\n",
       "      <td>1.115725</td>\n",
       "      <td>-1.033758</td>\n",
       "      <td>0.161263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.749049</td>\n",
       "      <td>0.472475</td>\n",
       "      <td>-1.311037</td>\n",
       "      <td>0.590795</td>\n",
       "      <td>-0.424628</td>\n",
       "      <td>-0.503666</td>\n",
       "      <td>0.747163</td>\n",
       "      <td>1.328334</td>\n",
       "      <td>-0.101280</td>\n",
       "      <td>-0.280176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8369</th>\n",
       "      <td>0.809561</td>\n",
       "      <td>0.772545</td>\n",
       "      <td>-0.603345</td>\n",
       "      <td>1.125781</td>\n",
       "      <td>-0.671348</td>\n",
       "      <td>0.540565</td>\n",
       "      <td>-0.407312</td>\n",
       "      <td>0.528993</td>\n",
       "      <td>-0.335991</td>\n",
       "      <td>0.178140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634721</td>\n",
       "      <td>0.056345</td>\n",
       "      <td>-1.487699</td>\n",
       "      <td>0.103556</td>\n",
       "      <td>-0.648218</td>\n",
       "      <td>-0.887477</td>\n",
       "      <td>0.445942</td>\n",
       "      <td>1.081470</td>\n",
       "      <td>0.609084</td>\n",
       "      <td>0.025298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8370 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.771931 -1.799955  1.313722 -1.630033  0.566290  1.589922 -0.172617   \n",
       "1     0.803999 -1.900528  1.245334 -1.692496  0.101666  2.042962  0.076518   \n",
       "2     0.872130 -2.032226  1.424598 -1.343837  0.161601  1.711995  0.503023   \n",
       "3     0.867914 -2.054812  1.657540 -0.838510  0.746273  1.227320  0.679350   \n",
       "4     0.787536 -2.011126  1.559197 -0.409157  1.239623  0.913107  0.641640   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8365  0.415159 -0.170777 -0.531934 -0.397453  1.102362 -0.267771  0.062068   \n",
       "8366  0.484640 -0.232514 -0.597377  0.039627  0.837373 -0.276658  0.205001   \n",
       "8367  0.558206 -0.163820 -0.476075  0.480464  0.879917 -0.589342 -0.360315   \n",
       "8368  0.591930  0.343880 -0.538673  1.014618  0.200438 -0.391132 -0.570871   \n",
       "8369  0.809561  0.772545 -0.603345  1.125781 -0.671348  0.540565 -0.407312   \n",
       "\n",
       "            7         8         9   ...        52        53        54  \\\n",
       "0     1.566368  0.659295  0.199667  ... -0.379306  1.641585 -0.743088   \n",
       "1     1.506671  0.006843  0.238603  ...  0.347120  1.752066 -0.985741   \n",
       "2     0.826614 -1.105172  0.270467  ... -0.585204  1.588777 -1.302961   \n",
       "3     1.134812 -0.876215  0.232273  ...  0.789144  1.273398 -1.416257   \n",
       "4     1.931937 -0.272880  0.127776  ...  0.377190  1.043657 -1.369488   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8365  1.148350 -2.241040  0.180624  ... -0.535923  1.136943 -0.416174   \n",
       "8366  1.321532 -2.205615  0.232497  ... -0.670336  1.115493 -0.641672   \n",
       "8367  1.203000 -2.164044  0.126000  ... -1.172690  0.839839 -1.031493   \n",
       "8368  1.115725 -1.033758  0.161263  ... -0.749049  0.472475 -1.311037   \n",
       "8369  0.528993 -0.335991  0.178140  ... -0.634721  0.056345 -1.487699   \n",
       "\n",
       "            55        56        57        58        59        60        61  \n",
       "0    -0.070795  0.742423  0.454864  0.251855  0.795493 -0.417825 -1.029987  \n",
       "1     0.049346  0.764168  0.594407  0.432133  1.080915 -0.165571 -1.420320  \n",
       "2     0.097989  0.733291  0.651646  0.515277  0.912816  0.289325 -1.499576  \n",
       "3    -0.048546  0.671334  0.746395  0.300846  0.709486  0.123002 -0.751547  \n",
       "4    -0.219058  0.751703  1.057360  0.347496  0.404459  0.330464  0.215042  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "8365  0.562862 -0.354710 -0.763675 -0.224326  0.846225 -1.504478 -0.403197  \n",
       "8366  0.649173 -0.423895 -0.589386 -0.034272  0.739777 -1.244535 -0.653119  \n",
       "8367  0.910849 -0.425116 -0.327954  0.842602  1.100344 -0.612106 -0.448852  \n",
       "8368  0.590795 -0.424628 -0.503666  0.747163  1.328334 -0.101280 -0.280176  \n",
       "8369  0.103556 -0.648218 -0.887477  0.445942  1.081470  0.609084  0.025298  \n",
       "\n",
       "[8370 rows x 62 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##make pandas dataframe for RF\n",
    "input = pd.DataFrame(inputvar)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6581e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 139)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##need to change this based on lag \n",
    "## 14-days = [:, 47:]\n",
    "## 20-days = [:, 53:]\n",
    "## 30-days = [:, 63:]\n",
    "\n",
    "temp = output.reshape(62, 182)\n",
    "temp = temp[:, 43:]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec04695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected indices\n",
    "##Europe\n",
    "#Index([1, 56, 0, 54, 9, 57, 55, 3, 26, 4], dtype='int64')\n",
    "\n",
    "##Nova\n",
    "#Index([1, 56, 0, 55, 2, 53, 54, 9, 4, 22], dtype='int64')\n",
    "\n",
    "##South\n",
    "#Index([1, 56, 54, 53, 55, 4, 3, 21, 14, 0], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b859756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pd datafram of selected feature columns.\n",
    "\n",
    "sele_ind_df = input[[1, 56, 54, 53, 55, 4, 3, 21, 14, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acb7fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>56</th>\n",
       "      <th>54</th>\n",
       "      <th>53</th>\n",
       "      <th>55</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>21</th>\n",
       "      <th>14</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.799955</td>\n",
       "      <td>0.742423</td>\n",
       "      <td>-0.743088</td>\n",
       "      <td>1.641585</td>\n",
       "      <td>-0.070795</td>\n",
       "      <td>0.566290</td>\n",
       "      <td>-1.630033</td>\n",
       "      <td>0.471726</td>\n",
       "      <td>0.035413</td>\n",
       "      <td>0.771931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.900528</td>\n",
       "      <td>0.764168</td>\n",
       "      <td>-0.985741</td>\n",
       "      <td>1.752066</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>-1.692496</td>\n",
       "      <td>0.557982</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.803999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.032226</td>\n",
       "      <td>0.733291</td>\n",
       "      <td>-1.302961</td>\n",
       "      <td>1.588777</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>-1.343837</td>\n",
       "      <td>0.245462</td>\n",
       "      <td>-0.013173</td>\n",
       "      <td>0.872130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.054812</td>\n",
       "      <td>0.671334</td>\n",
       "      <td>-1.416257</td>\n",
       "      <td>1.273398</td>\n",
       "      <td>-0.048546</td>\n",
       "      <td>0.746273</td>\n",
       "      <td>-0.838510</td>\n",
       "      <td>0.294595</td>\n",
       "      <td>-0.024929</td>\n",
       "      <td>0.867914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.011126</td>\n",
       "      <td>0.751703</td>\n",
       "      <td>-1.369488</td>\n",
       "      <td>1.043657</td>\n",
       "      <td>-0.219058</td>\n",
       "      <td>1.239623</td>\n",
       "      <td>-0.409157</td>\n",
       "      <td>-0.185676</td>\n",
       "      <td>-0.183715</td>\n",
       "      <td>0.787536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>-0.170777</td>\n",
       "      <td>-0.354710</td>\n",
       "      <td>-0.416174</td>\n",
       "      <td>1.136943</td>\n",
       "      <td>0.562862</td>\n",
       "      <td>1.102362</td>\n",
       "      <td>-0.397453</td>\n",
       "      <td>1.902774</td>\n",
       "      <td>0.188527</td>\n",
       "      <td>0.415159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>-0.232514</td>\n",
       "      <td>-0.423895</td>\n",
       "      <td>-0.641672</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>0.649173</td>\n",
       "      <td>0.837373</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>1.512352</td>\n",
       "      <td>0.213924</td>\n",
       "      <td>0.484640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8367</th>\n",
       "      <td>-0.163820</td>\n",
       "      <td>-0.425116</td>\n",
       "      <td>-1.031493</td>\n",
       "      <td>0.839839</td>\n",
       "      <td>0.910849</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>0.480464</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>-0.062387</td>\n",
       "      <td>0.558206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8368</th>\n",
       "      <td>0.343880</td>\n",
       "      <td>-0.424628</td>\n",
       "      <td>-1.311037</td>\n",
       "      <td>0.472475</td>\n",
       "      <td>0.590795</td>\n",
       "      <td>0.200438</td>\n",
       "      <td>1.014618</td>\n",
       "      <td>0.039851</td>\n",
       "      <td>-0.039619</td>\n",
       "      <td>0.591930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8369</th>\n",
       "      <td>0.772545</td>\n",
       "      <td>-0.648218</td>\n",
       "      <td>-1.487699</td>\n",
       "      <td>0.056345</td>\n",
       "      <td>0.103556</td>\n",
       "      <td>-0.671348</td>\n",
       "      <td>1.125781</td>\n",
       "      <td>-0.093596</td>\n",
       "      <td>0.205274</td>\n",
       "      <td>0.809561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8370 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         56        54        53        55        4         3   \\\n",
       "0    -1.799955  0.742423 -0.743088  1.641585 -0.070795  0.566290 -1.630033   \n",
       "1    -1.900528  0.764168 -0.985741  1.752066  0.049346  0.101666 -1.692496   \n",
       "2    -2.032226  0.733291 -1.302961  1.588777  0.097989  0.161601 -1.343837   \n",
       "3    -2.054812  0.671334 -1.416257  1.273398 -0.048546  0.746273 -0.838510   \n",
       "4    -2.011126  0.751703 -1.369488  1.043657 -0.219058  1.239623 -0.409157   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8365 -0.170777 -0.354710 -0.416174  1.136943  0.562862  1.102362 -0.397453   \n",
       "8366 -0.232514 -0.423895 -0.641672  1.115493  0.649173  0.837373  0.039627   \n",
       "8367 -0.163820 -0.425116 -1.031493  0.839839  0.910849  0.879917  0.480464   \n",
       "8368  0.343880 -0.424628 -1.311037  0.472475  0.590795  0.200438  1.014618   \n",
       "8369  0.772545 -0.648218 -1.487699  0.056345  0.103556 -0.671348  1.125781   \n",
       "\n",
       "            21        14        0   \n",
       "0     0.471726  0.035413  0.771931  \n",
       "1     0.557982  0.016162  0.803999  \n",
       "2     0.245462 -0.013173  0.872130  \n",
       "3     0.294595 -0.024929  0.867914  \n",
       "4    -0.185676 -0.183715  0.787536  \n",
       "...        ...       ...       ...  \n",
       "8365  1.902774  0.188527  0.415159  \n",
       "8366  1.512352  0.213924  0.484640  \n",
       "8367  0.629668 -0.062387  0.558206  \n",
       "8368  0.039851 -0.039619  0.591930  \n",
       "8369 -0.093596  0.205274  0.809561  \n",
       "\n",
       "[8370 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at new input array\n",
    "sele_ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab4cc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn input array into (# samples, 14 days, 10 features)\n",
    "sele_ind_data = sele_ind_df.values\n",
    "sele_ind_data1 = sele_ind_data.reshape(62,135,10)\n",
    "\n",
    "temp_flat = temp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09018bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8370, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sele_ind_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1230b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create timeseries data arrays for PCs \n",
    "new_input =  np.empty((62,126,10,10))\n",
    "new_output = np.empty((62,126))\n",
    "\n",
    "for i in range(0,62):\n",
    "    for j in range(0,126):\n",
    "        new_input[i,j,:,:] = sele_ind_data1[i,j:j+10,:]\n",
    "        new_output[i,j] = temp[i,j]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69d6f3d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "##create timeseries but select from 3 categories ...\n",
    "new_input = []\n",
    "new_output = []\n",
    "\n",
    "for i in range(14,9362):\n",
    "    print(i)\n",
    "    if temp_flat[i] == 0:\n",
    "        new_input.append(sele_ind_data[i-14:i,:])\n",
    "        new_output.append(temp_flat[i])\n",
    "    elif temp_flat[i] == 1:\n",
    "        new_input.append(sele_ind_data[i-14:i,:])\n",
    "        new_output.append(temp_flat[i])\n",
    "    if temp_flat[i] == 2:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb35597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 126, 10, 10)\n",
      "(62, 126)\n"
     ]
    }
   ],
   "source": [
    "new_input = np.array(new_input)\n",
    "new_output = np.array(new_output)\n",
    "print(new_input.shape)\n",
    "print(new_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0423e17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6445"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_ind = round((62*126)*0.175)\n",
    "frac_end = round((62*126)-frac_ind)\n",
    "frac_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53862551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5982e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set X_all and Y_all datasets\n",
    "X_all = np.copy(new_input.reshape((62*126),10,10))\n",
    "Y_all = np.copy(new_output.flatten())\n",
    "\n",
    "\n",
    "##training data partition out\n",
    "X_tri = X_all[:frac_end,:]\n",
    "Y_tri = Y_all[:frac_end]\n",
    "\n",
    "#testing data partition out\n",
    "X_tes = X_all[frac_end:,:]\n",
    "Y_tes = Y_all[frac_end:]\n",
    "\n",
    "#Convert the Y array into a categorical array. This means we will create one-hot vector labels for all of the inputs.\n",
    "# The one-hot vectors have an index for each possible output category (two in our case)\n",
    "# A \"1\" is put in the index corresponding to the category to which the sample belongs\n",
    "Y_all = keras.utils.to_categorical(Y_all)\n",
    "Y_tri = keras.utils.to_categorical(Y_tri)\n",
    "Y_tes= keras.utils.to_categorical(Y_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb186bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7812, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c49b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking my data for NaN of Infs because I need to make sure this doesn't cause\n",
    "#the model to throw back no loss\n",
    "\n",
    "if np.any(np.isnan(X_all)) or np.any(np.isinf(X_all)):\n",
    "    print(\"NaN or Inf values found in X_all!\")\n",
    "\n",
    "if np.any(np.isnan(Y_all)) or np.any(np.isinf(Y_all)):\n",
    "    print(\"NaN or Inf values found in Y_all!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a64b7",
   "metadata": {},
   "source": [
    "### Begin establishing specifics of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47cdb7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7812, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking to make sure shape was properly one hot encoded\n",
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a6f3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "##class weight creator for the instance where now I have a four dimensional output array \n",
    "def class_weight_creator(Y):\n",
    "    class_dict = {}\n",
    "    Y_reshaped = Y.reshape(-1, Y.shape[-1])\n",
    "    weights = np.max(np.sum(Y_reshaped, axis=0)) / np.sum(Y_reshaped, axis=0)\n",
    "    for i in range(Y.shape[-1] ):\n",
    "        class_dict[i] = weights[i]\n",
    "        \n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f4df8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##fraction of training data\\nX_validation = X_tri[0:frac_ind]\\nY_validation = Y_tri[0:frac_ind]\\n        \\nX_train = X_tri[frac_ind:len(X_tri)]\\nY_train = Y_tri[frac_ind:len(Y_tri)]\\n\\nX_test = X_tes\\nY_test = Y_tes'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##number of input nodes\n",
    "numb_int = X_all.shape[1:]\n",
    "\n",
    "'''##fraction of training data\n",
    "X_validation = X_tri[0:frac_ind]\n",
    "Y_validation = Y_tri[0:frac_ind]\n",
    "        \n",
    "X_train = X_tri[frac_ind:len(X_tri)]\n",
    "Y_train = Y_tri[frac_ind:len(Y_tri)]\n",
    "\n",
    "X_test = X_tes\n",
    "Y_test = Y_tes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2200e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02b7f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572bed9",
   "metadata": {},
   "source": [
    "### Model Architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74db2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "batch_size = 64 #The number of samples the network sees before it backpropagates (batch size)\n",
    "epochs = 50 #The number of times the network will loop through the entire dataset (epochs)\n",
    "shuffle = True #Set whether to shuffle the training data so the model doesn't see it sequentially \n",
    "verbose = 2 #Set whether the model will output information when trained (0 = no output; 2 = output accuracy every epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "806b59ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def categorical_focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Cross-entropy loss\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "\n",
    "        # Compute focal loss scaling factor\n",
    "        focal_factor = tf.pow(1 - y_pred, gamma)\n",
    "        loss = alpha * focal_factor * cross_entropy\n",
    "\n",
    "        return tf.reduce_sum(loss, axis=1)  # sum across classes per sample\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fa6b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_LSTM(hp): \n",
    "    ##set ranges for hyperparameters\n",
    "    n1 = hp.Int('n1', min_value=32, max_value=96, step=32)\n",
    "    n2 = hp.Int('n2', min_value=4, max_value=32, step=4)\n",
    "    n3 = hp.Int('n3', min_value=16, max_value=32, step=8)\n",
    "    \n",
    "    reg1 = hp.Float('reg1', min_value=0.001, max_value=0.9, step=0.001)\n",
    "    #reg2 = hp.Float('reg2', min_value=0.01, max_value=0.9, step=0.01)\n",
    "    reg3 = hp.Float('reg3', min_value=0.001, max_value=0.9, step=0.001)\n",
    "    \n",
    "    #alpha = hp.Float('alpha', 0.4, 0.8, step=0.1)\n",
    "    #gamma = hp.Float('gamma', 0.2, 1.0, step=0.2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    input_tensor = Input(shape=(10, 10))\n",
    "    layer1 = layers.RNN(\n",
    "        layers.LSTMCell(n1, activation='tanh', use_bias=True,\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2= reg1)),\n",
    "        return_sequences=True)(input_tensor)\n",
    "    layer2 = layers.RNN(\n",
    "        layers.LSTMCell(n2, activation='tanh', use_bias=True,\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2= reg1)))(layer1)\n",
    "    layer3 = layers.Dense(n3, activation='relu',use_bias=True,\n",
    "                          kernel_initializer='he_normal',bias_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2=reg3))(layer2)\n",
    "\n",
    "    output_tensor = layers.Dense(2, activation='softmax',)(layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    \n",
    "    lr = hp.Float('learning_rate', min_value=0.0001, max_value=0.1)\n",
    "    \n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    \n",
    "    #loss = categorical_focal_loss(alpha=alpha, gamma=gamma)\n",
    "    #decay_rate = lr / epochs\n",
    "    #momentum = 0.9\n",
    "\n",
    "    model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[keras.metrics.categorical_accuracy],)\n",
    "                            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18873d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##the LSTM layers will have EXACTLY the same regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb58d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "216e66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bae6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5f347d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rather than CVs, I am going to introduce k-fold validation instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be7779e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_kfold_tuning(X, Y, n_splits, epochs, batch_size):\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    all_best_hps = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        fold_id = str(fold+1)\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "        \n",
    "        tuner = kt.BayesianOptimization(\n",
    "            tune_LSTM,\n",
    "            objective=[kt.Objective('val_loss', 'min'), kt.Objective('val_categorical_accuracy', 'max')],\n",
    "            max_trials=150,\n",
    "            directory='tuning',\n",
    "            project_name=str(\"Eur_CV_Tk5_\"+fold_id))\n",
    "        \n",
    "        tuner.search(\n",
    "            X_train, Y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            batch_size=batch_size,callbacks=[stop_early],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        all_best_hps.append(best_hp)\n",
    "        \n",
    "    return all_best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "003889c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 15s]\n",
      "multi_objective: -0.004714846611022949\n",
      "\n",
      "Best multi_objective So Far: -0.004714846611022949\n",
      "Total elapsed time: 00h 01m 05s\n",
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |32                |n1\n",
      "12                |16                |n2\n",
      "32                |24                |n3\n",
      "0.414             |0.196             |reg1\n",
      "0.207             |0.254             |reg3\n",
      "0.005762          |0.0028757         |learning_rate\n",
      "\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - 2s 18ms/step - loss: 9.8665 - categorical_accuracy: 0.6633 - val_loss: 2.1764 - val_categorical_accuracy: 0.6501\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 1.2608 - categorical_accuracy: 0.6693 - val_loss: 0.8104 - val_categorical_accuracy: 0.6501\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 0.6953 - categorical_accuracy: 0.6693 - val_loss: 0.6619 - val_categorical_accuracy: 0.6501\n",
      "Epoch 4/30\n",
      " 6/81 [=>............................] - ETA: 0s - loss: 0.6574 - categorical_accuracy: 0.6562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#run tuning\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m \u001b[43mrun_kfold_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_tri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 22\u001b[0m, in \u001b[0;36mrun_kfold_tuning\u001b[0;34m(X, Y, n_splits, epochs, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m Y_train, Y_val \u001b[38;5;241m=\u001b[39m Y[train_idx], Y[val_idx]\n\u001b[1;32m     15\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mBayesianOptimization(\n\u001b[1;32m     16\u001b[0m     tune_LSTM,\n\u001b[1;32m     17\u001b[0m     objective\u001b[38;5;241m=\u001b[39m[kt\u001b[38;5;241m.\u001b[39mObjective(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m), kt\u001b[38;5;241m.\u001b[39mObjective(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[1;32m     18\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m     19\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuning\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEur_CV_Tk5_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfold_id))\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m best_hp \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m all_best_hps\u001b[38;5;241m.\u001b[39mappend(best_hp)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run tuning\n",
    "best_hps = run_kfold_tuning(X_tri, Y_tri, 5, 30, batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebebccfc",
   "metadata": {},
   "source": [
    "|Best Value So Far |Hyperparameter\n",
    "96                |96                |n1\n",
    "8                 |32                |n2\n",
    "24                |16                |n3\n",
    "0.693             |0.118             |reg1\n",
    "0.715             |0.869             |reg3\n",
    "0.066519          |0.0020381         |learning_rate\n",
    "\n",
    "\n",
    "|64                |n1\n",
    "|16                |n2\n",
    "|16                |n3\n",
    "|0.208             |reg1\n",
    "|0.177             |reg3\n",
    "|0.0006466         |learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a328503",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995d313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "lstm_model = tuner.hypermodel.build(best_hps)\n",
    "history = lstm_model.fit(X_train_cv,Y_train_cv, validation_data=(X_val_cv, Y_val_cv),\n",
    "                    batch_size=batch_size, epochs=epochs, shuffle=shuffle,class_weight = class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=lstm_model.history.history['loss']\n",
    "val_loss=lstm_model.history.history['val_loss']\n",
    "    \n",
    "cat_acc=lstm_model.history.history['categorical_accuracy']\n",
    "val_acc=lstm_model.history.history['val_categorical_accuracy']\n",
    "        \n",
    "pred = lstm_model.predict(X_all)\n",
    "pred_val = lstm_model.predict(X_val_cv)\n",
    "pred_train = lstm_model.predict(X_train_cv)\n",
    "pred_test = lstm_model.predict(X_tes)\n",
    "\n",
    "# Look at the optimization history\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=plt.figaspect(0.25))\n",
    "ax1.plot(train_loss, label='Training loss')\n",
    "ax1.plot(val_loss, label='Validation loss')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(cat_acc, label='Training ACC')\n",
    "ax2.plot(val_acc, label='Validation ACC')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Acc')\n",
    "ax2.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac2511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
