{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f66efd",
   "metadata": {},
   "source": [
    "### Tune the LSTM Model.\n",
    "Then maybe switching over to an LSTM model with an attention layer.\n",
    "\n",
    "File initially created 4/15/2025. \n",
    "\n",
    "I will start with a 14 day model. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5cdb115",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "!source ~/miniforge/bin/activate tf14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fed794",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.2.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m243.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m293.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.22.0 requires pyproj>=3.1.0, which is not installed.\n",
      "cartopy 0.22.0 requires pyshp>=2.1, which is not installed.\n",
      "cartopy 0.22.0 requires shapely>=1.7, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires colabtools, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires dinosaur-dycore, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires rtree, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires xarray_tensorstore, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 seaborn-0.13.2\n",
      "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.24.4)\n",
      "Collecting cftime (from netCDF4)\n",
      "  Downloading cftime-1.6.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Downloading cftime-1.6.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cftime\n",
      "Successfully installed cftime-1.6.4.post1\n",
      "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2023.6.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from xarray) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray) (1.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.4->xarray) (1.16.0)\n",
      "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.10.1)\n",
      "Collecting shapely>=1.7 (from cartopy)\n",
      "  Downloading shapely-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (23.2)\n",
      "Collecting pyshp>=2.1 (from cartopy)\n",
      "  Downloading pyshp-2.3.1-py2.py3-none-any.whl.metadata (55 kB)\n",
      "Collecting pyproj>=3.1.0 (from cartopy)\n",
      "  Downloading pyproj-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.1.0->cartopy) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->cartopy) (1.16.0)\n",
      "Downloading pyproj-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m196.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading shapely-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m343.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyshp, pyproj\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "graphcast 0.2.0.dev0 requires colabtools, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires dinosaur-dycore, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires rtree, which is not installed.\n",
      "graphcast 0.2.0.dev0 requires xarray_tensorstore, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyproj-3.7.1 pyshp-2.3.1 shapely-2.1.0\n",
      "Requirement already satisfied: investigate in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from investigate) (2.31.0)\n",
      "Collecting future (from investigate)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->investigate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->investigate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->investigate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->investigate) (2024.2.2)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: future\n",
      "Successfully installed future-1.0.0\n",
      "Requirement already satisfied: eofs in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from eofs) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner\n",
    "!pip install seaborn\n",
    "!pip install netCDF4\n",
    "!pip install xarray\n",
    "!pip install cartopy\n",
    "!pip install investigate\n",
    "!pip install eofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d0e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import cell makes its appearance once again...\n",
    "##so-called \"math\" related imports\n",
    "from netCDF4 import Dataset as ncread\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import math\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import xarray as xr\n",
    "\n",
    "import pickle\n",
    "\n",
    "##plotting related imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams #For changing text properties\n",
    "from cartopy import crs as ccrs #Useful for plotting maps\n",
    "import cartopy.util #Requires separate import\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "#import tensorflow/keras related files\n",
    "import tensorflow as tf    \n",
    "#tf.compat.v1.disable_v2_behavior() # <-- HERE !\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Activation, Reshape, Flatten, LSTM, Dense, Dropout, Embedding, Bidirectional, GRU\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import investigate\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ab0b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.15.0\n",
      "Keras Tuner: 1.4.7\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras Tuner:\", kt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea65648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EOF_def import EOF_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411ec5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load in solvers for PC analysis to get the PCs for the model itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d840f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input solvers\n",
    "infile = open(\"PVsolver_14days.p\",\"rb\",)\n",
    "PVsolver = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"EHFsolver_14days.p\",\"rb\",)\n",
    "EHFsolver = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"GPHsolver_14days.p\",\"rb\",)\n",
    "GPHsolver = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a8f80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (9362, 150)\n"
     ]
    }
   ],
   "source": [
    "## PV\n",
    "PV_EOF_nw, PV_EOF_nw2d, PV_eigenv, PV_VarEx, PV_PC = EOF_def(PVsolver, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f13005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (9362, 40)\n"
     ]
    }
   ],
   "source": [
    "## EHF\n",
    "EHF_EOF_nw, EHF_EOF_nw2d, EHF_eigenv, EHF_VarEx, EHF_PC = EOF_def(EHFsolver, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b234c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (9362, 10)\n"
     ]
    }
   ],
   "source": [
    "## GPH\n",
    "GPH_EOF_nw, GPH_EOF_nw2d, GPH_eigenv, GPH_VarEx, GPH_PC = EOF_def(GPHsolver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b452367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load output data\n",
    "infile = open(\"../../data/classed_europetemps_median.p\",\"rb\",)\n",
    "output = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ab47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create one array of PCs\n",
    "inputvar = np.concatenate((PV_PC,EHF_PC,GPH_PC),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "673da921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.408914</td>\n",
       "      <td>2.180526</td>\n",
       "      <td>-0.064847</td>\n",
       "      <td>0.479544</td>\n",
       "      <td>0.236225</td>\n",
       "      <td>-2.103696</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.191696</td>\n",
       "      <td>-0.672343</td>\n",
       "      <td>-0.139058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.955032</td>\n",
       "      <td>1.354215</td>\n",
       "      <td>0.545637</td>\n",
       "      <td>-0.317367</td>\n",
       "      <td>0.943791</td>\n",
       "      <td>0.312948</td>\n",
       "      <td>-0.047924</td>\n",
       "      <td>0.229463</td>\n",
       "      <td>-0.867954</td>\n",
       "      <td>-0.590789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.391230</td>\n",
       "      <td>1.978358</td>\n",
       "      <td>0.154025</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>-2.206385</td>\n",
       "      <td>-0.653936</td>\n",
       "      <td>-0.439157</td>\n",
       "      <td>-0.354834</td>\n",
       "      <td>-0.478178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.923370</td>\n",
       "      <td>1.414327</td>\n",
       "      <td>0.437932</td>\n",
       "      <td>-0.188792</td>\n",
       "      <td>0.926405</td>\n",
       "      <td>0.342297</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.385740</td>\n",
       "      <td>-0.605703</td>\n",
       "      <td>-0.688146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.979347</td>\n",
       "      <td>1.564503</td>\n",
       "      <td>-0.906574</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.060517</td>\n",
       "      <td>-0.945992</td>\n",
       "      <td>-0.209597</td>\n",
       "      <td>-2.807699</td>\n",
       "      <td>0.581650</td>\n",
       "      <td>-1.531468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855419</td>\n",
       "      <td>1.543970</td>\n",
       "      <td>0.538328</td>\n",
       "      <td>-0.096653</td>\n",
       "      <td>0.782070</td>\n",
       "      <td>0.392947</td>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.725281</td>\n",
       "      <td>-0.395176</td>\n",
       "      <td>-1.118037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.147069</td>\n",
       "      <td>2.107741</td>\n",
       "      <td>-0.771858</td>\n",
       "      <td>-0.015177</td>\n",
       "      <td>0.572812</td>\n",
       "      <td>-1.161453</td>\n",
       "      <td>1.584150</td>\n",
       "      <td>-1.876043</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-1.071449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796781</td>\n",
       "      <td>1.672516</td>\n",
       "      <td>0.787046</td>\n",
       "      <td>0.016755</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.532859</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>-0.154666</td>\n",
       "      <td>-1.536393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.061865</td>\n",
       "      <td>2.603007</td>\n",
       "      <td>-0.331819</td>\n",
       "      <td>-1.250306</td>\n",
       "      <td>0.514794</td>\n",
       "      <td>-2.566574</td>\n",
       "      <td>0.319776</td>\n",
       "      <td>-0.793118</td>\n",
       "      <td>-0.426587</td>\n",
       "      <td>-0.104066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672484</td>\n",
       "      <td>1.532088</td>\n",
       "      <td>1.128078</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.797032</td>\n",
       "      <td>0.601194</td>\n",
       "      <td>0.476338</td>\n",
       "      <td>0.833419</td>\n",
       "      <td>0.316101</td>\n",
       "      <td>-1.605322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>0.711699</td>\n",
       "      <td>0.110017</td>\n",
       "      <td>-0.622352</td>\n",
       "      <td>-0.490953</td>\n",
       "      <td>-0.536583</td>\n",
       "      <td>-0.223132</td>\n",
       "      <td>-1.081177</td>\n",
       "      <td>0.740292</td>\n",
       "      <td>-0.564920</td>\n",
       "      <td>1.517141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163487</td>\n",
       "      <td>0.164409</td>\n",
       "      <td>1.856498</td>\n",
       "      <td>1.191741</td>\n",
       "      <td>-0.842973</td>\n",
       "      <td>-0.517702</td>\n",
       "      <td>1.070749</td>\n",
       "      <td>0.458107</td>\n",
       "      <td>0.640005</td>\n",
       "      <td>1.496433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>0.624553</td>\n",
       "      <td>0.417414</td>\n",
       "      <td>-0.551925</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.163489</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>-1.110290</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>-0.091026</td>\n",
       "      <td>1.697813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317975</td>\n",
       "      <td>0.535626</td>\n",
       "      <td>1.920689</td>\n",
       "      <td>1.228516</td>\n",
       "      <td>-0.783687</td>\n",
       "      <td>-0.184219</td>\n",
       "      <td>1.066467</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>0.940192</td>\n",
       "      <td>0.547236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>0.160986</td>\n",
       "      <td>0.401613</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.268301</td>\n",
       "      <td>-0.432145</td>\n",
       "      <td>-0.138635</td>\n",
       "      <td>-0.038668</td>\n",
       "      <td>-0.238332</td>\n",
       "      <td>-0.095752</td>\n",
       "      <td>1.249798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458675</td>\n",
       "      <td>1.042271</td>\n",
       "      <td>1.865872</td>\n",
       "      <td>1.109565</td>\n",
       "      <td>-0.931445</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>1.265816</td>\n",
       "      <td>0.361846</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>-0.404878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>-0.088700</td>\n",
       "      <td>-0.367544</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>-0.405467</td>\n",
       "      <td>-0.435794</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.074697</td>\n",
       "      <td>0.536420</td>\n",
       "      <td>-0.085145</td>\n",
       "      <td>-0.210322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>1.285707</td>\n",
       "      <td>1.662183</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>-1.073229</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>1.727002</td>\n",
       "      <td>0.268285</td>\n",
       "      <td>0.652106</td>\n",
       "      <td>-0.748198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>-0.341670</td>\n",
       "      <td>-0.907566</td>\n",
       "      <td>-0.252993</td>\n",
       "      <td>-0.716137</td>\n",
       "      <td>-0.402094</td>\n",
       "      <td>-0.676333</td>\n",
       "      <td>-0.108086</td>\n",
       "      <td>0.501024</td>\n",
       "      <td>-0.491736</td>\n",
       "      <td>0.706784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705807</td>\n",
       "      <td>1.110381</td>\n",
       "      <td>1.475122</td>\n",
       "      <td>0.476560</td>\n",
       "      <td>-0.881305</td>\n",
       "      <td>-0.309092</td>\n",
       "      <td>1.865180</td>\n",
       "      <td>0.484964</td>\n",
       "      <td>0.493259</td>\n",
       "      <td>-0.564915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9362 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -3.408914  2.180526 -0.064847  0.479544  0.236225 -2.103696  0.075187   \n",
       "1    -3.391230  1.978358  0.154025  0.316228  0.067515 -2.206385 -0.653936   \n",
       "2    -2.979347  1.564503 -0.906574  0.275862  1.060517 -0.945992 -0.209597   \n",
       "3    -2.147069  2.107741 -0.771858 -0.015177  0.572812 -1.161453  1.584150   \n",
       "4    -3.061865  2.603007 -0.331819 -1.250306  0.514794 -2.566574  0.319776   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9357  0.711699  0.110017 -0.622352 -0.490953 -0.536583 -0.223132 -1.081177   \n",
       "9358  0.624553  0.417414 -0.551925  0.028200  0.163489  0.085617 -1.110290   \n",
       "9359  0.160986  0.401613  0.514232  0.268301 -0.432145 -0.138635 -0.038668   \n",
       "9360 -0.088700 -0.367544  0.045515 -0.405467 -0.435794  0.045745  0.074697   \n",
       "9361 -0.341670 -0.907566 -0.252993 -0.716137 -0.402094 -0.676333 -0.108086   \n",
       "\n",
       "           7         8         9    ...       190       191       192  \\\n",
       "0     0.191696 -0.672343 -0.139058  ... -0.955032  1.354215  0.545637   \n",
       "1    -0.439157 -0.354834 -0.478178  ... -0.923370  1.414327  0.437932   \n",
       "2    -2.807699  0.581650 -1.531468  ... -0.855419  1.543970  0.538328   \n",
       "3    -1.876043 -0.142993 -1.071449  ... -0.796781  1.672516  0.787046   \n",
       "4    -0.793118 -0.426587 -0.104066  ... -0.672484  1.532088  1.128078   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9357  0.740292 -0.564920  1.517141  ... -0.163487  0.164409  1.856498   \n",
       "9358  0.283400 -0.091026  1.697813  ... -0.317975  0.535626  1.920689   \n",
       "9359 -0.238332 -0.095752  1.249798  ... -0.458675  1.042271  1.865872   \n",
       "9360  0.536420 -0.085145 -0.210322  ... -0.621059  1.285707  1.662183   \n",
       "9361  0.501024 -0.491736  0.706784  ... -0.705807  1.110381  1.475122   \n",
       "\n",
       "           193       194       195       196       197       198       199  \n",
       "0    -0.317367  0.943791  0.312948 -0.047924  0.229463 -0.867954 -0.590789  \n",
       "1    -0.188792  0.926405  0.342297  0.039017  0.385740 -0.605703 -0.688146  \n",
       "2    -0.096653  0.782070  0.392947  0.188559  0.725281 -0.395176 -1.118037  \n",
       "3     0.016755  0.819336  0.532859  0.382354  0.999609 -0.154666 -1.536393  \n",
       "4     0.052643  0.797032  0.601194  0.476338  0.833419  0.316101 -1.605322  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9357  1.191741 -0.842973 -0.517702  1.070749  0.458107  0.640005  1.496433  \n",
       "9358  1.228516 -0.783687 -0.184219  1.066467  0.595146  0.940192  0.547236  \n",
       "9359  1.109565 -0.931445  0.042059  1.265816  0.361846  0.834360 -0.404878  \n",
       "9360  0.790136 -1.073229  0.049285  1.727002  0.268285  0.652106 -0.748198  \n",
       "9361  0.476560 -0.881305 -0.309092  1.865180  0.484964  0.493259 -0.564915  \n",
       "\n",
       "[9362 rows x 200 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##make pandas dataframe for RF\n",
    "input = pd.DataFrame(inputvar)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab588ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 151)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = output.reshape(62, 182)\n",
    "# temp = temp[:,26:177]\n",
    "temp = temp[:, 31:]\n",
    "#temp = temp.reshape(9362,)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5e7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected indices\n",
    "infile = open(\"../SelectIndices7_14days.p\",\"rb\",)\n",
    "sele_ind = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72dd2e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 16,  27,  54, 191, 192, 194, 198]),\n",
       " array([ 27,  49,  93, 153, 186, 192, 194]),\n",
       " array([106, 150, 164, 166, 178, 193, 194]),\n",
       " array([  6,  49, 157, 164, 192, 194, 199]),\n",
       " array([  1,   6,  35, 164, 171, 190, 194]),\n",
       " array([ 11,  21,  27, 153, 160, 192, 194]),\n",
       " array([ 27,  69, 120, 191, 192, 194, 198]),\n",
       " array([ 14,  49, 164, 190, 192, 194, 198]),\n",
       " array([ 22,  27, 163, 179, 192, 194, 198]),\n",
       " array([ 27,  64, 108, 159, 192, 194, 198]),\n",
       " array([ 69, 164, 185, 190, 193, 194, 195]),\n",
       " array([ 20,  27, 117, 157, 192, 194, 198]),\n",
       " array([ 27,  49, 151, 156, 182, 192, 194]),\n",
       " array([  3,  19, 114, 190, 191, 192, 194]),\n",
       " array([  3, 163, 168, 178, 191, 192, 194]),\n",
       " array([  6,  27,  59,  79, 164, 192, 194]),\n",
       " array([ 20,  27,  97, 157, 167, 192, 194]),\n",
       " array([ 27,  45,  49,  75, 191, 192, 194]),\n",
       " array([  5,  13,  20,  27, 157, 192, 194]),\n",
       " array([110, 150, 153, 164, 178, 192, 194]),\n",
       " array([ 14, 159, 160, 164, 193, 194, 195]),\n",
       " array([  6,  27, 156, 157, 182, 192, 194]),\n",
       " array([ 10, 157, 159, 161, 163, 164, 194]),\n",
       " array([  0,  41, 157, 164, 166, 191, 194]),\n",
       " array([ 49,  69,  90, 164, 191, 192, 194])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sele_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14a2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "##6, 27, 49, 157, 164, 192, 193, 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84a91ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pd datafram of selected feature columns.\n",
    "sele_ind_df = input[[4,27,49,69,153,157,164,192,194,198]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7401a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>27</th>\n",
       "      <th>49</th>\n",
       "      <th>69</th>\n",
       "      <th>153</th>\n",
       "      <th>157</th>\n",
       "      <th>164</th>\n",
       "      <th>192</th>\n",
       "      <th>194</th>\n",
       "      <th>198</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236225</td>\n",
       "      <td>-0.981309</td>\n",
       "      <td>-0.585172</td>\n",
       "      <td>0.756970</td>\n",
       "      <td>-0.364863</td>\n",
       "      <td>0.232701</td>\n",
       "      <td>-0.027525</td>\n",
       "      <td>0.545637</td>\n",
       "      <td>0.943791</td>\n",
       "      <td>-0.867954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.042728</td>\n",
       "      <td>-2.247280</td>\n",
       "      <td>-0.407302</td>\n",
       "      <td>0.224215</td>\n",
       "      <td>-0.114952</td>\n",
       "      <td>0.437932</td>\n",
       "      <td>0.926405</td>\n",
       "      <td>-0.605703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.060517</td>\n",
       "      <td>1.390004</td>\n",
       "      <td>-0.990492</td>\n",
       "      <td>0.204168</td>\n",
       "      <td>-0.440378</td>\n",
       "      <td>0.187351</td>\n",
       "      <td>0.053405</td>\n",
       "      <td>0.538328</td>\n",
       "      <td>0.782070</td>\n",
       "      <td>-0.395176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.572812</td>\n",
       "      <td>0.795751</td>\n",
       "      <td>1.241412</td>\n",
       "      <td>0.358838</td>\n",
       "      <td>-0.370544</td>\n",
       "      <td>0.271584</td>\n",
       "      <td>-0.017319</td>\n",
       "      <td>0.787046</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>-0.154666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514794</td>\n",
       "      <td>0.419198</td>\n",
       "      <td>1.229085</td>\n",
       "      <td>0.906907</td>\n",
       "      <td>-0.262513</td>\n",
       "      <td>0.253980</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>1.128078</td>\n",
       "      <td>0.797032</td>\n",
       "      <td>0.316101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>-0.536583</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>0.521495</td>\n",
       "      <td>-1.227881</td>\n",
       "      <td>0.703444</td>\n",
       "      <td>-0.085629</td>\n",
       "      <td>-0.075188</td>\n",
       "      <td>1.856498</td>\n",
       "      <td>-0.842973</td>\n",
       "      <td>0.640005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>0.163489</td>\n",
       "      <td>1.201930</td>\n",
       "      <td>-0.416038</td>\n",
       "      <td>-0.301073</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>0.079014</td>\n",
       "      <td>-0.168279</td>\n",
       "      <td>1.920689</td>\n",
       "      <td>-0.783687</td>\n",
       "      <td>0.940192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>-0.432145</td>\n",
       "      <td>1.573980</td>\n",
       "      <td>0.038797</td>\n",
       "      <td>-0.087340</td>\n",
       "      <td>0.283284</td>\n",
       "      <td>-0.131557</td>\n",
       "      <td>0.541103</td>\n",
       "      <td>1.865872</td>\n",
       "      <td>-0.931445</td>\n",
       "      <td>0.834360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>-0.435794</td>\n",
       "      <td>0.430842</td>\n",
       "      <td>-1.116483</td>\n",
       "      <td>0.221247</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>-0.149581</td>\n",
       "      <td>0.515335</td>\n",
       "      <td>1.662183</td>\n",
       "      <td>-1.073229</td>\n",
       "      <td>0.652106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>-0.402094</td>\n",
       "      <td>2.001950</td>\n",
       "      <td>-0.981616</td>\n",
       "      <td>1.308604</td>\n",
       "      <td>0.033017</td>\n",
       "      <td>0.053154</td>\n",
       "      <td>0.595771</td>\n",
       "      <td>1.475122</td>\n",
       "      <td>-0.881305</td>\n",
       "      <td>0.493259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9362 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           4         27        49        69        153       157       164  \\\n",
       "0     0.236225 -0.981309 -0.585172  0.756970 -0.364863  0.232701 -0.027525   \n",
       "1     0.067515  0.009088  0.042728 -2.247280 -0.407302  0.224215 -0.114952   \n",
       "2     1.060517  1.390004 -0.990492  0.204168 -0.440378  0.187351  0.053405   \n",
       "3     0.572812  0.795751  1.241412  0.358838 -0.370544  0.271584 -0.017319   \n",
       "4     0.514794  0.419198  1.229085  0.906907 -0.262513  0.253980  0.005631   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9357 -0.536583  1.000348  0.521495 -1.227881  0.703444 -0.085629 -0.075188   \n",
       "9358  0.163489  1.201930 -0.416038 -0.301073  0.535926  0.079014 -0.168279   \n",
       "9359 -0.432145  1.573980  0.038797 -0.087340  0.283284 -0.131557  0.541103   \n",
       "9360 -0.435794  0.430842 -1.116483  0.221247  0.132725 -0.149581  0.515335   \n",
       "9361 -0.402094  2.001950 -0.981616  1.308604  0.033017  0.053154  0.595771   \n",
       "\n",
       "           192       194       198  \n",
       "0     0.545637  0.943791 -0.867954  \n",
       "1     0.437932  0.926405 -0.605703  \n",
       "2     0.538328  0.782070 -0.395176  \n",
       "3     0.787046  0.819336 -0.154666  \n",
       "4     1.128078  0.797032  0.316101  \n",
       "...        ...       ...       ...  \n",
       "9357  1.856498 -0.842973  0.640005  \n",
       "9358  1.920689 -0.783687  0.940192  \n",
       "9359  1.865872 -0.931445  0.834360  \n",
       "9360  1.662183 -1.073229  0.652106  \n",
       "9361  1.475122 -0.881305  0.493259  \n",
       "\n",
       "[9362 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at new input array\n",
    "sele_ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abe8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn input array into (# samples, 14 days, 10 features)\n",
    "sele_ind_data = sele_ind_df.values\n",
    "sele_ind_data1 = sele_ind_data.reshape(62,151,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38cf7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create timeseries data arrays for PCs \n",
    "new_input =  np.empty((62,137,14,10))\n",
    "new_output = np.empty((62,137))\n",
    "\n",
    "for i in range(0,62):\n",
    "    for j in range(14,151):\n",
    "        new_input[i,j-14,:,:] = sele_ind_data1[i,j-14:j,:]\n",
    "        new_output[i,j-14] = temp[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b609e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8494, 14, 10)\n",
      "(8494,)\n"
     ]
    }
   ],
   "source": [
    "new_input = new_input.reshape((62*137, 14, 10))\n",
    "new_output = new_output.reshape((62*137))\n",
    "print(new_input.shape)\n",
    "print(new_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3eee9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set X_all and Y_all datasets\n",
    "X_all = np.copy(new_input)\n",
    "Y_all = np.copy(new_output)\n",
    "\n",
    "##training data partition out\n",
    "X_tri = X_all[:57*137,:]\n",
    "Y_tri = Y_all[:57*137]\n",
    "\n",
    "#testing data partition out\n",
    "X_tes = X_all[57*137:,:]\n",
    "Y_tes = Y_all[57*137:]\n",
    "\n",
    "#Convert the Y array into a categorical array. This means we will create one-hot vector labels for all of the inputs.\n",
    "# The one-hot vectors have an index for each possible output category (two in our case)\n",
    "# A \"1\" is put in the index corresponding to the category to which the sample belongs\n",
    "Y_all = keras.utils.to_categorical(Y_all)\n",
    "Y_tri = keras.utils.to_categorical(Y_tri)\n",
    "Y_tes= keras.utils.to_categorical(Y_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7928b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking my data for NaN of Infs because I need to make sure this doesn't cause\n",
    "#the model to throw back no loss\n",
    "\n",
    "if np.any(np.isnan(X_all)) or np.any(np.isinf(X_all)):\n",
    "    print(\"NaN or Inf values found in X_all!\")\n",
    "\n",
    "if np.any(np.isnan(Y_all)) or np.any(np.isinf(Y_all)):\n",
    "    print(\"NaN or Inf values found in Y_all!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b69e1",
   "metadata": {},
   "source": [
    "### Begin establishing specifics of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e295ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##set 5 years of data for validation\n",
    "frac_ind = 5*137\n",
    "frac_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec24f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8494, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking to make sure shape was properly one hot encoded\n",
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80a092eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##class weight creator for the instance where now I have a four dimensional output array \n",
    "def class_weight_creator(Y):\n",
    "    class_dict = {}\n",
    "    Y_reshaped = Y.reshape(-1, Y.shape[-1])\n",
    "    weights = np.max(np.sum(Y_reshaped, axis=0)) / np.sum(Y_reshaped, axis=0)\n",
    "    for i in range(Y.shape[-1] ):\n",
    "        class_dict[i] = weights[i]\n",
    "        \n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edf25819",
   "metadata": {},
   "outputs": [],
   "source": [
    "##number of input nodes\n",
    "numb_int = X_all.shape[1:]\n",
    "\n",
    "##fraction of training data\n",
    "X_validation = X_tri[0:frac_ind]\n",
    "Y_validation = Y_tri[0:frac_ind]\n",
    "        \n",
    "X_train = X_tri[frac_ind:len(X_tri)]\n",
    "Y_train = Y_tri[frac_ind:len(Y_tri)]\n",
    "\n",
    "X_test = X_tes\n",
    "Y_test = Y_tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7fd45e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7124, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac40b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7340e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.7601705}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##do the class_dict weights\n",
    "class_weight = class_weight_creator(Y_train)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe8700",
   "metadata": {},
   "source": [
    "### Model Architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfa11ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "batch_size = 256 #The number of samples the network sees before it backpropagates (batch size)\n",
    "epochs = 50 #The number of times the network will loop through the entire dataset (epochs)\n",
    "shuffle = True #Set whether to shuffle the training data so the model doesn't see it sequentially \n",
    "verbose = 2 #Set whether the model will output information when trained (0 = no output; 2 = output accuracy every epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a31653f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def basic_LSTM(n2, n3, rl2, rl3,lr):  \n",
    "    input_tensor = Input(shape=(numb_int[0], numb_int[1]))\n",
    "    #layer1 = layers.LSTM(n1, activation='tanh', return_sequences=True, use_bias=True,\n",
    "                          #kernel_initializer='glorot_uniform',\n",
    "                          #kernel_regularizer=keras.regularizers.l2(l2= rl1))(input_tensor)\n",
    "    layer2 = layers.LSTM(n2, activation='tanh', use_bias=True,\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2= rl2))(input_tensor)\n",
    "    layer3 = layers.Dense(n3, activation='relu',use_bias=True,\n",
    "                          kernel_initializer='he_normal',bias_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l2=rl3))(layer2)\n",
    "\n",
    "    output_tensor = layers.Dense(2, activation='softmax',)(layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    #decay_rate = lr / epochs\n",
    "    #momentum = 0.9\n",
    "\n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=[keras.metrics.categorical_accuracy],)\n",
    "                            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3416d42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(model=basic_LSTM,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=2,\n",
    "                        class_weight=class_weight)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'n2': np.arange(64,192,32),\n",
    "              'n3': np.arange(16,64,4),\n",
    "              'rl2': np.arange(0.001,0.1,0.01),\n",
    "              'rl3': np.arange(0.001,0.1,0.01),\n",
    "              'lr': np.arange(0.01,0.1,0.01)}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=3,refit=False, scoring=\"accuracy\", n_jobs = -1)\n",
    "\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88a1a750",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best accuracy of: %f using %s\" % (grid_result.best_score_, \n",
    "                                         grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33ffc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_LSTM(hp): \n",
    "    ##set ranges for hyperparameters\n",
    "    n2 = hp.Int('n2', min_value=64, max_value=256, step=32)\n",
    "    n3 = hp.Int('n3', min_value=16, max_value=64, step=4)\n",
    "    \n",
    "    #reg1 = hp.Float('reg1', min_value=0.01, max_value=0.1, sampling='LOG', default=0.01)\n",
    "    reg2 = hp.Float('reg2', min_value=0.0001, max_value=0.009)\n",
    "    reg3 = hp.Float('reg3', min_value=0.0001, max_value=0.009)\n",
    "    input_tensor = Input(shape=(numb_int[0], numb_int[1]))\n",
    "    #layer1 = layers.LSTM(n1, activation='tanh', return_sequences=True, use_bias=True,\n",
    "                          #kernel_initializer='glorot_uniform',\n",
    "                          #kernel_regularizer=keras.regularizers.l2(l2= rl1))(input_tensor)\n",
    "    layer2 = layers.LSTM(n2, activation='tanh', use_bias=True,\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(l2= reg2))(input_tensor)\n",
    "    layer3 = layers.Dense(n3, activation='relu',use_bias=True,\n",
    "                          kernel_initializer='he_normal',bias_initializer='he_normal',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(l2=reg3))(layer2)\n",
    "\n",
    "    output_tensor = layers.Dense(2, activation='softmax',)(layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    lr = hp.Float('learning_rate', min_value=1e-2, max_value=0.09)\n",
    "    \n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=[tf.keras.metrics.categorical_accuracy],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a62d0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ba0a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8124663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:48:19.000876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78670 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:44:00.0, compute capability: 9.0\n"
     ]
    }
   ],
   "source": [
    "#intialize/setup the hyperband tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    tune_LSTM, #model\n",
    "    objective = [kt.Objective('val_loss', 'min'), kt.Objective('loss', 'min'),\n",
    "                kt.Objective('val_categorical_accuracy', 'max')], #target\n",
    "    max_trials=1000, #number of iterations of tuning to run\n",
    "    max_consecutive_failed_trials=3, #number of allowed failed trials\n",
    "    directory = 'tuning',\n",
    "    project_name='EOF_attempt1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65c0a9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae659ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 05s]\n",
      "multi_objective: 0.9077216572402769\n",
      "\n",
      "Best multi_objective So Far: 0.9077216572402769\n",
      "Total elapsed time: 00h 00m 05s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |224               |n2\n",
      "60                |40                |n3\n",
      "0.0065611         |0.0062507         |reg2\n",
      "0.0036985         |0.0077102         |reg3\n",
      "0.088657          |0.027165          |learning_rate\n",
      "\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Train on 7124 samples, validate on 685 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:48:24.510599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78670 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:44:00.0, compute capability: 9.0\n",
      "2025-04-25 18:48:24.551726: W tensorflow/c/c_api.cc:305] Operation '{name:'training/Adam/beta_2/Assign' id:623 op device:{requested: '', assigned: ''} def:{{{node training/Adam/beta_2/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/beta_2, training/Adam/beta_2/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##actual tuning process\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[1;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:4605\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4596\u001b[0m \u001b[38;5;66;03m# Refresh callable if anything has changed.\u001b[39;00m\n\u001b[1;32m   4597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4599\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4603\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m   4604\u001b[0m ):\n\u001b[0;32m-> 4605\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_symbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4607\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn(\u001b[38;5;241m*\u001b[39marray_vals, run_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_metadata)\n\u001b[1;32m   4608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:4530\u001b[0m, in \u001b[0;36mGraphExecutionFunction._make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   4528\u001b[0m     callable_opts\u001b[38;5;241m.\u001b[39mrun_options\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_options)\n\u001b[1;32m   4529\u001b[0m \u001b[38;5;66;03m# Create callable.\u001b[39;00m\n\u001b[0;32m-> 4530\u001b[0m callable_fn \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable_from_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallable_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4531\u001b[0m \u001b[38;5;66;03m# Cache parameters corresponding to the generated callable, so that\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m \u001b[38;5;66;03m# we can detect future mismatches and refresh the callable.\u001b[39;00m\n\u001b[1;32m   4533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;241m=\u001b[39m callable_fn\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py:1538\u001b[0m, in \u001b[0;36mBaseSession._make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a handle to a \"callable\" with the given options.\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03m  A handle to the new callable.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Callable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallable_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py:1496\u001b[0m, in \u001b[0;36mBaseSession._Callable.__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1493\u001b[0m options_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBufferFromString(\n\u001b[1;32m   1494\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_bytes(callable_options\u001b[38;5;241m.\u001b[39mSerializeToString()))\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionMakeCallable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m      \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m   tf_session\u001b[38;5;241m.\u001b[39mTF_DeleteBuffer(options_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##actual tuning process\n",
    "tuner.search(X_train, Y_train, validation_data=(X_validation, Y_validation),\n",
    "             batch_size=batch_size, epochs=epochs, shuffle=shuffle,\n",
    "             class_weight = class_weight, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "lstm_model = tuner.hypermodel.build(best_hps)\n",
    "history = lstm_model.fit(X_train,Y_train, validation_data=(X_validation, Y_validation),\n",
    "                    batch_size=batch_size, epochs=epochs, shuffle=shuffle,class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=lstm_model.history.history['loss']\n",
    "val_loss=lstm_model.history.history['val_loss']\n",
    "    \n",
    "cat_acc=lstm_model.history.history['categorical_accuracy']\n",
    "val_acc=lstm_model.history.history['val_categorical_accuracy']\n",
    "        \n",
    "pred = lstm_model.predict(X_all)\n",
    "pred_val = lstm_model.predict(X_validation)\n",
    "pred_train = lstm_model.predict(X_train)\n",
    "pred_test = lstm_model.predict(X_test)\n",
    "\n",
    "# Look at the optimization history\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=plt.figaspect(0.25))\n",
    "ax1.plot(train_loss, label='Training loss')\n",
    "ax1.plot(val_loss, label='Validation loss')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(cat_acc, label='Training ACC')\n",
    "ax2.plot(val_acc, label='Validation ACC')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Acc')\n",
    "ax2.legend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
